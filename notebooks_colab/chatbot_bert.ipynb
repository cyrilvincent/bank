{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 731,
     "status": "ok",
     "timestamp": 1705077071636,
     "user": {
      "displayName": "Grégory Deschamps",
      "userId": "00349060252068867806"
     },
     "user_tz": -60
    },
    "id": "03HDN2SVyC20",
    "outputId": "5f1fa9a2-fa2a-4726-bfd7-28d491bab012"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.11.3\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "fZ-WkRrJyQ4M"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\conta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\conta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow_estimator\\python\\estimator\\util.py:74: The name tf.train.SessionRunHook is deprecated. Please use tf.estimator.SessionRunHook instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\conta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow_hub\\native_module.py:92: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\conta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow_hub\\saved_model_module.py:40: The name tf.saved_model.constants.LEGACY_INIT_OP_KEY is deprecated. Please use tf.compat.v1.saved_model.constants.LEGACY_INIT_OP_KEY instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import pickle\n",
    "from typing import List\n",
    "import numpy as np\n",
    "import os\n",
    "import tempfile\n",
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15835,
     "status": "ok",
     "timestamp": 1705077096099,
     "user": {
      "displayName": "Grégory Deschamps",
      "userId": "00349060252068867806"
     },
     "user_tz": -60
    },
    "id": "MC0xiOzcydSr",
    "outputId": "59d9a8ad-d457-44fd-e074-996ca4bf242a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/tfhub_modules\n",
      "module https://tfhub.dev/google/universal-sentence-encoder/4 loaded\n"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "print(os.path.join(tempfile.gettempdir(), \"tfhub_modules\"))\n",
    "module_url = \"https://tfhub.dev/google/universal-sentence-encoder/4\" #\"https://tfhub.dev/google/universal-sentence-encoder-lite/2\" #\"https://tfhub.dev/google/universal-sentence-encoder/4\" #\"https://tfhub.dev/google/universal-sentence-encoder-large/5\"\n",
    "model = hub.load(module_url)\n",
    "print (\"module %s loaded\" % module_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MMp02l5Gy0Qt"
   },
   "outputs": [],
   "source": [
    "# POO\n",
    "class Item:\n",
    "\n",
    "    def __init__(self, question, answer):\n",
    "        self.question = question\n",
    "        self.answer = answer\n",
    "        self.embed = None\n",
    "\n",
    "class BertUseService:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.items: List[Item] = []\n",
    "\n",
    "    def embed(self, s: str):\n",
    "        return model([s])[0].numpy()\n",
    "\n",
    "    def score(self, l1: List[float], l2: List[float]) -> float:\n",
    "        return np.inner(l1, l2)\n",
    "\n",
    "    def train(self, path: str):\n",
    "        print(\"Training\")\n",
    "        with open(path, encoding=\"utf-8\") as f:\n",
    "            reader = csv.DictReader(f, delimiter=\"|\")\n",
    "            for row in reader:\n",
    "                q = row[\"question\"]\n",
    "                r = row[\"answer\"]\n",
    "                if r is not None and r.strip() != \"\":\n",
    "                    item = Item(q, r)\n",
    "                    item.embed = self.embed(q)\n",
    "                    self.items.append(item)\n",
    "        print(\"\\nSaving\")\n",
    "        with open(path.replace(\".txt\", \"_model.pickle\"), \"wb\") as f:\n",
    "            pickle.dump(self.items, f)\n",
    "\n",
    "    def load_model(self, path):\n",
    "        print(\"Load model\")\n",
    "        with open(path, \"rb\") as f:\n",
    "            self.items = pickle.load(f)\n",
    "\n",
    "    def predict(self, s: str):\n",
    "        embed = self.embed(s)\n",
    "        best_score = 0\n",
    "        best_item = None\n",
    "        for item in self.items:\n",
    "            score = self.score(embed, item.embed)\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_item = item\n",
    "                if best_score > 0.99:\n",
    "                    break\n",
    "        return best_item, best_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6753,
     "status": "ok",
     "timestamp": 1705077169364,
     "user": {
      "displayName": "Grégory Deschamps",
      "userId": "00349060252068867806"
     },
     "user_tz": -60
    },
    "id": "J-BCS9thzla6",
    "outputId": "66ef58ca-e5bd-4f73-f49a-73dce28e2cec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n",
      "\n",
      "Saving\n",
      "Load model\n",
      "> Bonjour\n",
      "Comment allez vous? @100%\n"
     ]
    }
   ],
   "source": [
    "service = BertUseService()\n",
    "service.train(\"data/chatbot/dialogs_fr.txt\")\n",
    "service.load_model(\"data/chatbot/dialogs_fr_model.pickle\")\n",
    "print(\"> Bonjour\")\n",
    "res = service.predict(\"Bonjour\")\n",
    "print(f\"{res[0].answer} @{res[1] * 100:.0f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 643
    },
    "executionInfo": {
     "elapsed": 78672,
     "status": "error",
     "timestamp": 1705077254455,
     "user": {
      "displayName": "Grégory Deschamps",
      "userId": "00349060252068867806"
     },
     "user_tz": -60
    },
    "id": "Z1oCpqa_z2_a",
    "outputId": "2d7e4e30-28b6-467b-9da7-6c887d2b611e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> je vais bien merci et vous ?\n",
      "Je suis assez bien. Merci d'avoir posé la question. @82%\n",
      "> je vais bien merci et vous ?\n",
      "Je suis assez bien. Merci d'avoir posé la question. @82%\n",
      "> qu'est ce que vous racontez de beau ?\n",
      "l'île est si verte et l'eau est si bleue. @57%\n",
      "> tu racontes n'importe quoi\n",
      "je parle principalement à la radio. @60%\n",
      "> quelle radio ?\n",
      "j'écoute jour et nuit. @65%\n",
      "> oui mais laquelle ?\n",
      "ils ont dit qu'environ 30 maisons avaient été entièrement brûlées  @54%\n",
      "> c'est énorme !\n",
      "quelle est la taille de « assez gros » ?  @75%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-f01d31027913>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"> \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mservice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{res[0].answer} @{res[1] * 100:.0f}%\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    s = input(\"> \")\n",
    "    res = service.predict(s)\n",
    "    print(f\"{res[0].answer} @{res[1] * 100:.0f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F1JOFSpQaKc_"
   },
   "source": [
    "# Nouvelle section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Enjg-oQ1aK2k"
   },
   "source": [
    "# Nouvelle section"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
